{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ulzee/dev/ml/_data/inception/model/\n",
      "/Users/ulzee/dev/ml/_data/inception/model/classify_image_graph_def.pb\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import data_paths\n",
    "import cifar10, inception\n",
    "from inception import transfer_values_cache\n",
    "from food import food_labels, food_examples\n",
    "\n",
    "print inception.data_dir\n",
    "path_graph_def = \"classify_image_graph_def.pb\"\n",
    "model_path = os.path.join(inception.data_dir, path_graph_def)\n",
    "print model_path\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    with tf.gfile.FastGFile(model_path, 'rb') as file:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(file.read())\n",
    "        tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "        # Name of the tensor for feeding the input image as jpeg.\n",
    "tensor_name_input_jpeg = \"DecodeJpeg/contents:0\"\n",
    "\n",
    "# Name of the tensor for feeding the decoded input image.\n",
    "# Use this for feeding images in other formats than jpeg.\n",
    "tensor_name_input_image = \"DecodeJpeg:0\"\n",
    "\n",
    "# Name of the tensor for the resized input image.\n",
    "# This is used to retrieve the image after it has been resized.\n",
    "tensor_name_resized_image = \"ResizeBilinear:0\"\n",
    "\n",
    "# Name of the tensor for the output of the softmax-classifier.\n",
    "# This is used for classifying images with the Inception model.\n",
    "tensor_name_softmax = \"softmax:0\"\n",
    "\n",
    "# Name of the tensor for the unscaled outputs of the softmax-classifier (aka. logits).\n",
    "tensor_name_softmax_logits = \"softmax/logits:0\"\n",
    "\n",
    "# Name of the tensor for the output of the Inception model.\n",
    "# This is used for Transfer Learning.\n",
    "tensor_name_transfer_layer = \"pool_3:0\"\n",
    "# Get the output of the Inception model by looking up the tensor\n",
    "# with the appropriate name for the output of the softmax-classifier.\n",
    "y_pred = graph.get_tensor_by_name(tensor_name_softmax)\n",
    "\n",
    "# Get the unscaled outputs for the Inception model (aka. softmax-logits).\n",
    "y_logits = graph.get_tensor_by_name(tensor_name_softmax_logits)\n",
    "\n",
    "# Get the tensor for the resized image that is input to the neural network.\n",
    "resized_image = graph.get_tensor_by_name(tensor_name_resized_image)\n",
    "\n",
    "# Get the tensor for the last layer of the graph, aka. the transfer-layer.\n",
    "transfer_layer = graph.get_tensor_by_name(tensor_name_transfer_layer)\n",
    "\n",
    "# Get the number of elements in the transfer-layer.\n",
    "transfer_len = transfer_layer.get_shape()[3]\n",
    "\n",
    "# Create a TensorFlow session for executing the graph.\n",
    "in_session = tf.Session(graph=graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31395 ('/Users/ulzee/dev/ml/_data/FOOD256/data/1/1-filled.jpg', 'rice', '1')\n"
     ]
    }
   ],
   "source": [
    "labels = food_labels()\n",
    "flattened_examples = []\n",
    "for lbl in labels:\n",
    "    examples = food_examples(lbl, load_images=False)\n",
    "    flattened_examples += [(one, lbl.name, lbl.id) for one in examples]\n",
    "print len(flattened_examples), flattened_examples[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('/Users/ulzee/dev/ml/_data/FOOD256/data/188/311898-filled.jpg', 'beef in oyster sauce', '188')\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "shuffle(flattened_examples)\n",
    "print flattened_examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31393 2\n"
     ]
    }
   ],
   "source": [
    "set_size = len(flattened_examples)\n",
    "num_reserved = 2\n",
    "train_set, test_set = flattened_examples[:-num_reserved], flattened_examples[-num_reserved:]\n",
    "print len(train_set), len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048 256\n"
     ]
    }
   ],
   "source": [
    "print transfer_len, len(labels)\n",
    "x = tf.placeholder(tf.float32, shape=[None, transfer_len], name='x')\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, len(labels)], name='y_true')\n",
    "y_correct = tf.argmax(y_true, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prettytensor as pt\n",
    "x_pretty = pt.wrap(x)\n",
    "\n",
    "with pt.defaults_scope(activation_fn=tf.nn.relu):\n",
    "    y_output, loss = x_pretty                                        \\\n",
    "        .fully_connected(size=len(labels), name='PTT_layer_fc1')    \\\n",
    "        .softmax_classifier(num_classes=len(labels), labels=y_true)\n",
    "\n",
    "global_step = tf.Variable(initial_value=0, name='global_step', trainable=False)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(loss, global_step)\n",
    "y_guess = tf.argmax(y_output, axis=1)\n",
    "y_is_correct = tf.equal(y_guess, y_correct)\n",
    "accuracy = tf.reduce_mean(tf.cast(y_is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def in_create_feed_dict(image_path, image=None):\n",
    "    if image is not None:\n",
    "        # Image is passed in as a 3-dim array that is already decoded.\n",
    "        feed_dict = {tensor_name_input_image: image}\n",
    "\n",
    "    elif image_path is not None:\n",
    "        # Read the jpeg-image as an array of bytes.\n",
    "        image_data = tf.gfile.FastGFile(image_path, 'rb').read()\n",
    "\n",
    "        # Image is passed in as a jpeg-encoded image.\n",
    "        feed_dict = {tensor_name_input_jpeg: image_data}\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Either image or image_path must be set.\")\n",
    "\n",
    "    return feed_dict\n",
    "\n",
    "def classify(image_path):\n",
    "    # Create a feed-dict for the TensorFlow graph with the input image.\n",
    "    feed_dict = in_create_feed_dict(image_path)\n",
    "\n",
    "    # Execute the TensorFlow session to get the predicted labels.\n",
    "    pred = in_session.run(transfer_layer, feed_dict=feed_dict)\n",
    "\n",
    "    # Reduce the array to a single dimension.\n",
    "    pred = np.squeeze(pred)\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prelim results: (array([False, False], dtype=bool), array([81, 79]), ['180', '233'])\n"
     ]
    }
   ],
   "source": [
    "# Split the data-set in batches of this size to limit RAM usage.\n",
    "batch_size = 256\n",
    "\n",
    "def predict_cls(transfer_values, labels, true_ys):\n",
    "    # Number of images.\n",
    "    num_images = len(transfer_values)\n",
    "\n",
    "    # Allocate an array for the predicted classes which\n",
    "    # will be calculated in batches and filled into this array.\n",
    "    guessed_ys = np.zeros(shape=num_images, dtype=np.int)\n",
    "\n",
    "    # Now calculate the predicted classes for the batches.\n",
    "    # We will just iterate through all the batches.\n",
    "    # There might be a more clever and Pythonic way of doing this.\n",
    "\n",
    "    # The starting index for the next batch is denoted i.\n",
    "    i = 0\n",
    "\n",
    "    while i < num_images:\n",
    "        # The ending index for the next batch is denoted j.\n",
    "        j = min(i + batch_size, num_images)\n",
    "\n",
    "        # Create a feed-dict with the images and labels\n",
    "        # between index i and j.\n",
    "        feed_dict = {x: transfer_values[i:j],\n",
    "                     y_true: labels[i:j]}\n",
    "\n",
    "        # Calculate the predicted class using TensorFlow.\n",
    "        guessed_ys[i:j] = session.run(y_guess, feed_dict=feed_dict)\n",
    "\n",
    "        # Set the start-index for the next batch to the\n",
    "        # end-index of the current batch.\n",
    "        i = j\n",
    "        \n",
    "    # Create a boolean array whether each image is correctly classified.\n",
    "    correct = np.in1d(true_ys, guessed_ys)\n",
    "\n",
    "#     return list(correct), list(guessed_ys), list(true_ys)\n",
    "    return (correct), (guessed_ys), list(true_ys)\n",
    "\n",
    "def vectorize_id(idnum):\n",
    "    vec = np.zeros((len(labels)))\n",
    "    vec[int(idnum) - 1] = 1\n",
    "    return vec\n",
    "\n",
    "def predict_cls_test():\n",
    "    paths, names, ids = zip(*test_set)\n",
    "    return predict_cls(transfer_values = [classify(one) for one in paths],\n",
    "                       labels = [vectorize_id(one) for one in ids],\n",
    "                       true_ys = ids)\n",
    "\n",
    "print 'Prelim results:', predict_cls_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_test_accuracy():\n",
    "    correct, cls_pred, _ = predict_cls_test()\n",
    "    acc, num_correct = correct.mean(), correct.sum()\n",
    "    num_images = len(correct)\n",
    "    msg = \"Accuracy on Test-Set: {0:.1%} ({1} / {2})\"\n",
    "    print(msg.format(acc, num_correct, num_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 0.0% (0 / 2)\n"
     ]
    }
   ],
   "source": [
    "print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Step:      1, Training Batch Accuracy:   0.0%\n",
      "Global Step:      2, Training Batch Accuracy:   0.0%\n",
      "Global Step:      3, Training Batch Accuracy:   0.0%\n",
      "Global Step:      4, Training Batch Accuracy:   0.0%\n",
      "Global Step:      5, Training Batch Accuracy:   0.0%\n",
      "Global Step:      6, Training Batch Accuracy:   0.0%\n",
      "Global Step:      7, Training Batch Accuracy:   0.0%\n",
      "Global Step:      8, Training Batch Accuracy:   0.0%\n",
      "Global Step:      9, Training Batch Accuracy:   0.0%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-d29cc968babf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-64-d29cc968babf>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(num_iterations)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtrain_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_true_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-d29cc968babf>\u001b[0m in \u001b[0;36mrandom_batch\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mx_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mone\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvectorize_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mone\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-adf17364658a>\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Execute the TensorFlow session to get the predicted labels.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransfer_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# Reduce the array to a single dimension.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ulzee/dev/ml/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ulzee/dev/ml/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ulzee/dev/ml/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ulzee/dev/ml/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ulzee/dev/ml/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def random_batch():\n",
    "    batch_size = 1\n",
    "    idx = list(np.random.choice(len(train_set), batch_size, replace=False))\n",
    "    batch = []\n",
    "    for ii, item in enumerate(train_set):\n",
    "        if ii in idx:\n",
    "            batch.append(item)\n",
    "    paths, names, ids = zip(*batch)\n",
    "\n",
    "    x_batch = [classify(one) for one in paths]\n",
    "    y_batch = [vectorize_id(one) for one in ids]\n",
    "\n",
    "    return x_batch, y_batch\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    for i in range(num_iterations):\n",
    "        x_batch, y_true_batch = random_batch()\n",
    "\n",
    "        train_input = {x: x_batch, y_true: y_true_batch}\n",
    "        i_global, _ = session.run([global_step, optimizer], feed_dict=train_input)\n",
    "\n",
    "        if (i_global % 1 == 0) or (i == num_iterations - 1):\n",
    "            batch_acc = session.run(accuracy, feed_dict=train_input)\n",
    "            msg = \"Global Step: {0:>6}, Training Batch Accuracy: {1:>6.1%}\"\n",
    "#             print(msg.format(i_global, batch_acc))\n",
    "            print(msg.format(i_global, batch_acc))\n",
    "\n",
    "session.run(tf.global_variables_initializer())\n",
    "optimize(num_iterations=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
